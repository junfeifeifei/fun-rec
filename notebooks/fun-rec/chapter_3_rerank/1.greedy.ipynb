{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e42047f",
   "metadata": {},
   "source": [
    "# 基于贪心的重排\n",
    ":label:`greedy_rerank`\n",
    "\n",
    "贪心算法以其思路直观、计算高效、易于实现的特点，成为重排阶段解决多样性、新颖性等问题的首选策略之一。它们通常不依赖复杂的模型训练，而是基于预先定义的规则或目标函数，通过逐步选择当前最优解（贪心选择）的方式来构建或调整最终推荐列表。本节将深入剖析两种经典的、基于贪心的重排算法：最大边际相关（Maximal Marginal Relevance, MMR） 和 行列式点过程（Determinantal Point Process, DPP）。\n",
    "\n",
    "## MMR：最大边际相关\n",
    "\n",
    "在精排输出的按CTR降序排列的列表中，头部物品往往具有高度相似性（如连续推荐同品类商品或同风格视频）。这种同质化现象直接导致两大问题：\n",
    "\n",
    "1. 用户体验恶化：用户浏览时产生审美疲劳，兴趣衰减速度加快；\n",
    "2. 系统效率损失：长尾优质内容曝光不足，平台生态多样性下降。\n",
    "\n",
    "MMR算法 :cite:`carbonell1998use` 的核心目标是在保留高相关性物品的前提下，通过主动引入多样性打破同质化，实现“相关性与多样性的帕累托最优”。\n",
    "\n",
    "MMR通过定义边际收益函数量化物品对列表的增量价值：\n",
    "\n",
    "$$\n",
    "MR(i) = \\lambda \\cdot \\underbrace{\\text{Rel}(i)}_{\\text{相关性}} - (1-\\lambda) \\cdot \\underbrace{\\max_{j \\in S} \\text{Sim}(i,j)}_{\\text{多样性惩罚项}}\n",
    "$$\n",
    "\n",
    "其中：\n",
    "\n",
    "- $S$：已选物品集合\n",
    "\n",
    "- $\\text{Rel}(i)$：物品$i$的相关性分数，直接继承精排模型输出（如CTR预估分）\n",
    "\n",
    "- $\\text{Sim}(i,j)$：物品$i$与$j$的相似度，计算方式包括：\n",
    "\n",
    "- $\\lambda$：权衡参数 ($0 \\leq \\lambda \\leq 1$)\n",
    "    - $\\lambda \\to 1$：退化为精排序（纯相关性优先）\n",
    "    - $\\lambda \\to 0$：强制多样性优先（可能牺牲相关性）\n",
    "\n",
    "当精排候选内容数量太多的时候，可以通过滑动窗口来对齐进行优化，也就是计算相似度的时候不是直接计算所有的相似度，而是计算窗口内的相似度，\n",
    "$$\n",
    "MR_{\\text{win}}(i) = \\lambda \\cdot \\text{Rel}(i) - (1-\\lambda) \\cdot \\underbrace{\\max_{j \\in W} \\text{Sim}(i,j)}_{\\text{窗口多样性惩罚}}\n",
    "$$\n",
    "其中$W \\subseteq S$是最近选择的$w$个物品（$w = |W| \\ll |S|$）。\n",
    "\n",
    "\n",
    "MMR核心代码实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "855ee93d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T06:19:07.871106Z",
     "iopub.status.busy": "2025-10-13T06:19:07.870515Z",
     "iopub.status.idle": "2025-10-13T06:19:08.757280Z",
     "shell.execute_reply": "2025-10-13T06:19:08.751930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选择了 3 个物品\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from typing import Any, Callable, Dict, List\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "class Item:\n",
    "    def __init__(\n",
    "        self,\n",
    "        id: str,\n",
    "        rel: float,\n",
    "        dense_vector: List[float] = None,\n",
    "        sparse_features: Dict[str, Any] = None\n",
    "    ):\n",
    "        self.id = id\n",
    "        self.rel = rel  # 相关性分数（精排分）\n",
    "        self.dense_vector = dense_vector  # 稠密向量表示（如嵌入向量）\n",
    "        self.sparse_features = sparse_features  # 稀疏特征（标签、类别、作者等）\n",
    "\n",
    "def MMR_Reranking(\n",
    "    item_pool: List[Item],\n",
    "    k: int,\n",
    "    lambda_param: float,  # 权衡参数\n",
    "    sim_func: Callable[[Item, Item], float],  # 相似度计算函数\n",
    "    window_size: int = None  # 滑动窗口大小\n",
    ") -> List[Item]:\n",
    "    \"\"\"\n",
    "    基于最大边际相关(MMR)算法的重排实现，支持滑动窗口优化\n",
    "\n",
    "    参数:\n",
    "    item_pool -- 候选物品列表\n",
    "    k -- 最终返回的物品数量\n",
    "    lambda_param -- 相关性与多样性权衡参数 (0-1)\n",
    "    sim_func -- 物品相似度计算函数\n",
    "    window_size -- 滑动窗口大小，默认为None（使用所有已选物品）\n",
    "\n",
    "    返回:\n",
    "    重排后的物品列表\n",
    "    \"\"\"\n",
    "    # 创建副本避免修改原始输入\n",
    "    candidates = copy.deepcopy(item_pool)\n",
    "    S = []  # 初始化重排结果列表\n",
    "\n",
    "    if not candidates:\n",
    "        return S\n",
    "\n",
    "    # 第一步：选取精排最高分物品\n",
    "    first_item = max(candidates, key=lambda x: x.rel)\n",
    "    S.append(first_item)\n",
    "    candidates.remove(first_item)\n",
    "\n",
    "    # 第二步：贪心迭代选择\n",
    "    while len(S) < k and candidates:\n",
    "        best_score = -float('inf')\n",
    "        best_item = None\n",
    "\n",
    "        # 确定要考虑的已选物品窗口\n",
    "        if window_size and len(S) > window_size:\n",
    "            # 只使用最近选择的window_size个物品\n",
    "            window = S[-window_size:]\n",
    "        else:\n",
    "            # 使用所有已选物品\n",
    "            window = S\n",
    "\n",
    "        for item in candidates:\n",
    "            # 计算与窗口中物品的最大相似度\n",
    "            max_sim = max(sim_func(item, s) for s in window) if window else 0\n",
    "\n",
    "            # 使用MMR公式: MR(i) = $\\lambda$ * Rel(i) - (1 - $\\lambda$) * max_sim(i, window)\n",
    "            score = lambda_param * item.rel - (1 - lambda_param) * max_sim\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_item = item\n",
    "\n",
    "        if best_item:\n",
    "            S.append(best_item)\n",
    "            candidates.remove(best_item)\n",
    "        else:\n",
    "            break  # 无有效候选时退出\n",
    "\n",
    "    return S\n",
    "\n",
    "def cosine_similarity(x, y):\n",
    "    vec1 = np.array(x.dense_vector)\n",
    "    vec2 = np.array(y.dense_vector)\n",
    "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
    "\n",
    "\n",
    "# 生成测试数据\n",
    "item_size = 1000\n",
    "feature_dimension = 100\n",
    "max_length = 50\n",
    "\n",
    "# 创建测试物品\n",
    "test_items = []\n",
    "for i in range(item_size):\n",
    "    rel_score = np.exp(0.01 * np.random.randn() + 0.2)\n",
    "    dense_vec = np.random.randn(feature_dimension)\n",
    "    dense_vec /= norm(dense_vec)  # 归一化\n",
    "\n",
    "    item = Item(\n",
    "        id=f\"item_{i}\",\n",
    "        rel=rel_score,\n",
    "        dense_vector=dense_vec.tolist()\n",
    "    )\n",
    "    test_items.append(item)\n",
    "\n",
    "# 计算相似度\n",
    "sim_func = cosine_similarity\n",
    "# 滑动窗口大小\n",
    "window_size = 3\n",
    "# 权衡参数\n",
    "lambda_param = 0.7\n",
    "# 重排\n",
    "reranked_items = MMR_Reranking(test_items, 3, lambda_param, sim_func, window_size)\n",
    "# 输出结果\n",
    "print(f'选择了 {len(reranked_items)} 个物品')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32989139",
   "metadata": {},
   "source": [
    "假如有5个待重排的物品，已知精排打分和item之间的两两相似度，重排需要从5个物品中筛选出top3条内容的详细计算流程如下：\n",
    "1. 假设候选集包含5个商品及其精排分（Rel），相似度矩阵如下：\n",
    "\n",
    "| 商品 | Rel | A   | B   | C   | D   | E   |\n",
    "|------|-----|-----|-----|-----|-----|-----|\n",
    "| A    | 0.95| 1.0 | 0.2 | 0.8 | 0.1 | 0.3 |\n",
    "| B    | 0.90| 0.2 | 1.0 | 0.1 | 0.7 | 0.4 |\n",
    "| C    | 0.85| 0.8 | 0.1 | 1.0 | 0.3 | 0.6 |\n",
    "| D    | 0.80| 0.1 | 0.7 | 0.3 | 1.0 | 0.5 |\n",
    "| E    | 0.75| 0.3 | 0.4 | 0.6 | 0.5 | 1.0 |\n",
    "\n",
    "2. $\\lambda=0.7$时的MMR过程：\n",
    "    1. 初始选择：A (Rel=0.95)\n",
    "    2. 第二轮计算： \n",
    "    ```\n",
    "    B: 0.90 - 0.7*max(Sim(A,B)=0.2) = 0.90 - 0.14 = 0.76\n",
    "    C: 0.85 - 0.7*0.8 = 0.85 - 0.56 = 0.29\n",
    "    D: 0.80 - 0.7*0.1 = 0.80 - 0.07 = 0.73\n",
    "    E: 0.75 - 0.7*0.3 = 0.75 - 0.21 = 0.54\n",
    "    ```\n",
    "        选择 B (score=0.76)\n",
    "    3. 第三轮计算（对比当前列表S=[A,B]）：\n",
    "    ```\n",
    "    C: 0.85 - 0.7*max(Sim(A,C)=0.8, Sim(B,C)=0.1) = 0.85-0.56=0.29\n",
    "    D: 0.80 - 0.7*max(0.1, 0.7) = 0.80-0.49=0.31 \n",
    "    E: 0.75 - 0.7*max(0.3, 0.4) = 0.75-0.28=0.47\n",
    "    ```\n",
    "        选择 E (score=0.47)\n",
    "    4. 最终序列: [A, B, E] (对比精排序[A, B, C] 多样性提升37%)\n",
    "\n",
    "## DPP：行列式点过程\n",
    "\n",
    "### 行列式如何度量多样性\n",
    "\n",
    "上述MMR原理中可以看出，MMR通过候选内容和已选内容计算两两相似度，贪心的选择一个和已选所有内容相似度最低的内容。这种方式无法捕捉多个物品间的复杂排斥关系（如三个相似物品的冗余效应），而行列式可以实现这一点。为了解释清楚行列式如何度量多样性，下面会花一定的篇幅做详细的介绍。\n",
    "\n",
    "假设我们通过余弦相似度的方式来计算物品之间的相似度，对于每一个物品都有一个向量表示$x_i$，那么对于待排序的所有物品$X$，很容易得到所有物品两两之间的相似度矩阵$S=X^TX$。\n",
    "\n",
    "我们知道矩阵行列式的几何意义表示的是，矩阵列向量张成的超面体的\"有向体积\"。在矩阵$S$中，如果列向量都线性相关，意味着列向量\"塌缩\"在更低维的空间中（在2D中，两个向量共线；在3D中，三个向量共面），此时矩阵$S$的行列式$det(S)=0$。反之，如果线性不相关，向量张成的高纬空间没有冗余，线性不相关。\n",
    "\n",
    "假如我们有4个物品，对应的标签分别为：$a=\\text{科幻动作片},b=\\text{科幻喜剧片},c=\\text{古装爱情片},d=\\text{古装悬疑片}$，计算物品之间的两两相似度，得到相似度矩阵$S_t$，物品${a,b,c,d}$的相似度矩阵：\n",
    "$$\n",
    "S = \\begin{pmatrix}\n",
    "1 & 0.9 & 0.1 & 0.2 \\\\\n",
    "0.9 & 1 & 0.1 & 0.1 \\\\\n",
    "0.1 & 0.1 & 1 & 0.8 \\\\\n",
    "0.2 & 0.1 & 0.8 & 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "分别计算物品 ${a,b}$ 和物品 ${b,d}$ 的相似度矩阵 $S_{a,b}$ 和 $S_{b,d}$：\n",
    "\n",
    "$$\n",
    "S_{a,b} = \\begin{pmatrix}\n",
    "1 & 0.9 \\\\\n",
    "0.9 & 1\n",
    "\\end{pmatrix},\n",
    "$$\n",
    "\n",
    "$$\n",
    "S_{b,d} = \\begin{pmatrix}\n",
    "1 & 0.1 \\\\\n",
    "0.1 & 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "它们的行列式分别为：\n",
    "\n",
    "- $|S_{a,b}|=1*1-0.9*0.9=0.19$\n",
    "\n",
    "- $|S_{b,d}|=1*1-0.1*0.1=0.81$\n",
    "\n",
    "从行列式的结果可以看出，当相似度矩阵的行列式值较大时，对应物品的多样性越高，反之行列式的值越低，多样性越低。\n",
    "\n",
    "### 相关性与多样性融合\n",
    "\n",
    "在推荐中，相关性和多样性是两个重要的指标。相关性指的是物品之间的相似性，即物品的相关性越高，推荐的结果越相似。在DPP中，通过引入一个半正定的核矩阵$L$来同时优化物品的相关性和多样性。该半正定核矩阵可以分解为$L=B^TB$，其中$B$的每一列表示重排候选集中物品的表示向量。具体来说，$B$的向量是通过相关性得分$r_i$和归一化后的物品向量的乘积计算得来。因此核矩阵中的元素$L_{i,j}$可以表示为：\n",
    "\n",
    "$$\n",
    "\\mathbf{L}_{ij} = \\langle \\mathbf{B}_i, \\mathbf{B}_j \\rangle = \\langle r_i \\mathbf{f}_i, r_j \\mathbf{f}_j \\rangle = r_i r_j \\langle \\mathbf{f}_i, \\mathbf{f}_j \\rangle.\n",
    "$$\n",
    "\n",
    "其中，$\\langle \\mathbf{f}_i, \\mathbf{f}_j \\rangle$表示物品$i$和物品$j$的内积，即相似度得分$S_{ij}$。因此，核矩阵$L$可以进一步表示为：\n",
    "\n",
    "$$\\mathbf{L} = \\text{Diag}(\\mathbf{r}) \\cdot \\mathbf{S} \\cdot \\text{Diag}(\\mathbf{r})$$\n",
    ":eqlabel:`eq-dpp-kernel`\n",
    "\n",
    "即分别对相似性矩阵的每一行和每一列分别乘以$r_i$。\n",
    "\n",
    "在公式推导之前，我们看一个核矩阵的详细构造过程，假设我们有 3 个物品，它们之间的相似度矩阵 $S$ 如下：\n",
    "$$\n",
    "S = \\begin{bmatrix}\n",
    "1 & 0.8 & 0.2 \\\\\n",
    "0.8 & 1 & 0.6 \\\\\n",
    "0.2 & 0.6 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "相关性向量 $r$ ：\n",
    "$$\n",
    "r = \\begin{bmatrix}\n",
    "0.9 \\\\\n",
    "0.7 \\\\\n",
    "0.5\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "构建对角阵：\n",
    "$$\n",
    "\\text{Diag}(r) = \\begin{bmatrix}\n",
    "0.9 & 0 & 0 \\\\\n",
    "0 & 0.7 & 0 \\\\\n",
    "0 & 0 & 0.5\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "计算核矩阵：\n",
    "$$\n",
    "L = \\text{Diag}(r) \\cdot S \\cdot \\text{Diag}(r)\n",
    "$$\n",
    "首先计算$\\text{Diag}(r) \\cdot S$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{Diag}(r) \\cdot S &= \\begin{bmatrix}\n",
    "0.9 & 0 & 0 \\\\\n",
    "0 & 0.7 & 0 \\\\\n",
    "0 & 0 & 0.5\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1 & 0.8 & 0.2 \\\\\n",
    "0.8 & 1 & 0.6 \\\\\n",
    "0.2 & 0.6 & 1\n",
    "\\end{bmatrix} \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "0.9 & 0.72 & 0.18 \\\\\n",
    "0.56 & 0.7 & 0.42 \\\\\n",
    "0.1 & 0.3 & 0.5\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "然后计算 $(\\text{Diag}(r) \\cdot S) \\cdot \\text{Diag}(r)$：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "(\\text{Diag}(r) \\cdot S) \\cdot \\text{Diag}(r) &= \\begin{bmatrix}\n",
    "0.9 & 0.72 & 0.18 \\\\\n",
    "0.56 & 0.7 & 0.42 \\\\\n",
    "0.1 & 0.3 & 0.5\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0.9 & 0 & 0 \\\\\n",
    "0 & 0.7 & 0 \\\\\n",
    "0 & 0 & 0.5\n",
    "\\end{bmatrix} \\\\\n",
    "&= \\begin{bmatrix}\n",
    "0.81 & 0.504 & 0.09 \\\\\n",
    "0.504 & 0.49 & 0.21 \\\\\n",
    "0.09 & 0.21 & 0.25\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "构建完核矩阵后，继续 :eqref:`eq-dpp-kernel` 推导，根据行列式的乘法性质可得到：\n",
    "$$\n",
    "|L| = |\\text{Diag}(r)| \\cdot |S| \\cdot |\\text{Diag}(r)| = \\prod_{i \\in R} r_{i}^2 \\cdot |S|\n",
    "$$\n",
    "\n",
    "对于用户$u$来说，被选中的候选物品集合为$R_u$，核矩阵的行列式表示为：\n",
    "$$\n",
    "|L_{R_u}| = \\prod_{i \\in R_u} r_{u,i}^2 \\cdot |S|\n",
    "$$\n",
    "两边取对数，得到：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\log |L_{R_u}| = \\sum_{i \\in R_u} \\log r_{u,i}^2 + \\log |S|\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "其中：\n",
    "\n",
    "- 第一项只跟\"相关性\"有关，越相关 $r_{u,i}^2$ 越大；\n",
    "\n",
    "- 第二项 $\\log |S|$ 只跟\"多样性\"有关，S 越接近正交（余弦越接近 0），行列式越大。\n",
    "\n",
    "经过上述的简单推到，我们会发现DPP最终优化的目标也变成了类似MMR的相关性和多样性的线形组合。所以在实际应用时会通过一个超参$\\theta$来平衡相关性和多样性的权重。\n",
    "\n",
    "$$\n",
    "\\log |L_{R_u}| = \\theta \\sum_{i \\in R_u} \\log r_{u,i}^2 + (1-\\theta) \\log |S|\n",
    "$$\n",
    "\n",
    "\n",
    "### 贪心求解过程\n",
    "\n",
    "上述介绍了相似矩阵的行列式可以度量多样性，通过核矩阵可以融合相关性和多样性，下面继续来看一下贪心求解的过程。重排从物品候选列表中选择一个子集，使得$\\log |L_{R_u}|$的值最大需要通过DPP（行列式点过程）来实现。\n",
    "\n",
    "DPP是一种性能较高的概率模型，能将复杂的概率计算转换成简单的行列式计算，通过核矩阵的行列式计算每一个子集的概率，这一筛选过程就是行列式点过程的最大后验概率推断MAP（maximum a posteriori inference），行列式点过程的MAP求解是一个复杂的过程，Hulu的论文中提出了一种改进的贪心算法能够快速求解 :cite:`chen2018fast`。\n",
    "\n",
    "这一求解过程简单来说就是每次从候选集中贪心地选择一个能使边际收益（Marginal Gain）最大的商品加入到最终的结果子集中，直到满足停止条件为止，即每次选择物品$j$添加到结果集$Y_g$中，$Y_g$初始化为空集，物品$j$需要满足下面的等式：\n",
    "\n",
    "$$j = \\arg\\max_{i \\in Z \\setminus Y_g} \\log\\det(\\mathbf{L}_{Y_g \\cup \\{i\\}}) - \\log\\det(\\mathbf{L}_{Y_g})$$\n",
    ":eqlabel:`eq-dpp-marginal-gain`\n",
    "\n",
    "由于$L$是一个半正定矩阵，所有主子矩阵也都是半正定矩阵，假设$det(L_{Y_g}) > 0$，$det(L_{Y_g})$的Cholesky分解可以表示为$L_{Y_g}=VV^T$，其中$V$是一个可逆的下三角矩阵。\n",
    "\n",
    "对于新加入的物品$i$，我们构造构造一个新的矩阵$\\mathbf{L}_{Y_g \\cup \\{i\\}}$，它包含了$L_{Y_g}$和新物品$i$相关的元素，新增物品$i$后的核矩阵$\\mathbf{L}_{Y_g \\cup \\{i\\}}$的Cholesky分解为：\n",
    "\n",
    "\n",
    "$$\\mathbf{L}_{Y_g \\cup \\{i\\}} = \\begin{bmatrix} \\mathbf{L}_{Y_g} & \\mathbf{L}_{Y_g,i} \\\\ \\mathbf{L}_{i,Y_g} & \\mathbf{L}_{ii} \\end{bmatrix} = \\begin{bmatrix} \\mathbf{V} & \\mathbf{0} \\\\ \\mathbf{c}_i & d_i \\end{bmatrix} \\begin{bmatrix} \\mathbf{V} & \\mathbf{0} \\\\ \\mathbf{c}_i & d_i \\end{bmatrix}^\\top = \\begin{bmatrix} V V^\\top & V c_i^\\top \\\\[4pt] c_i V^\\top & c_i c_i^\\top+ d_i^2 \\end{bmatrix} $$\n",
    ":eqlabel:`eq-dpp-cholesky`\n",
    "\n",
    "\n",
    "其中：\n",
    "\n",
    "- $\\mathbf{V}$ 是已选择物品集合 $Y_g$ 对应的Cholesky分解的下三角矩阵\n",
    "\n",
    "- $\\mathbf{L}_{Y_g,i}$ 是核矩阵 $\\mathbf{L}$ 中已选择物品集合 $Y_g$ 与候选物品 $i$ 之间的相关性向量\n",
    "\n",
    "- $L_{ii}$ 是核矩阵 $\\mathbf{L}$ 中物品 $i$ 的对角元素，$r_i r_i \\langle \\mathbf{f}_i, \\mathbf{f}_i \\rangle=r_i^2$\n",
    "\n",
    "此外，行向量$c_i$和标量$d_i$满足如下条件：\n",
    "\n",
    "$$\n",
    "\\mathbf{V} \\mathbf{c}_i^\\top = \\mathbf{L}_{Y_g,i}\n",
    "$$\n",
    "\n",
    "$$\n",
    "d_i^2 = \\mathbf{L}_{ii} - \\|\\mathbf{c}_i\\|_2^2.\n",
    "$$\n",
    "\n",
    "因此，$c_i$和$d_i$可以求解得到：\n",
    "\n",
    "- $c_i^T = V^T \\mathbf{L}_{Y_g,i}$\n",
    "\n",
    "- $d_i = \\sqrt{\\mathbf{L}_{ii} - \\|\\mathbf{c}_i\\|_2^2}$\n",
    "\n",
    "\n",
    "根据 :eqref:`eq-dpp-cholesky` 公式，我们有Cholesky分解的分块形式：\n",
    "$$\n",
    "\\mathbf{L}_{Y_g \\cup \\{i\\}} = \\begin{bmatrix} \\mathbf{L}_{Y_g} & \\mathbf{L}_{Y_g,i} \\\\ \\mathbf{L}_{i,Y_g} & \\mathbf{L}_{ii} \\end{bmatrix} = \\begin{bmatrix} \\mathbf{V} & \\mathbf{0} \\\\ \\mathbf{c}_i & d_i \\end{bmatrix} \\begin{bmatrix} \\mathbf{V} & \\mathbf{0} \\\\ \\mathbf{c}_i & d_i \\end{bmatrix}^T\n",
    "$$\n",
    "\n",
    "设 $\\mathbf{M} = \\begin{bmatrix} \\mathbf{V} & \\mathbf{0} \\\\ \\mathbf{c}_i & d_i \\end{bmatrix}$，则：\n",
    "$$\n",
    "\\mathbf{L}_{Y_g \\cup \\{i\\}} = \\mathbf{M}\\mathbf{M}^T\n",
    "$$\n",
    "\n",
    "根据矩阵行列式的性质：\n",
    "$$\n",
    "\\det(\\mathbf{L}_{Y_g \\cup \\{i\\}}) = \\det(\\mathbf{M}\\mathbf{M}^T) = \\det(\\mathbf{M}) \\cdot \\det(\\mathbf{M}^T) = \\det(\\mathbf{M})^2\n",
    "$$\n",
    "\n",
    "由于 $\\mathbf{M}$ 是分块下三角矩阵，其行列式等于对角块行列式的乘积：\n",
    "$$\n",
    "\\det(\\mathbf{M}) = \\det(\\mathbf{V}) \\cdot \\det(d_i) = \\det(\\mathbf{V}) \\cdot d_i\n",
    "$$\n",
    "\n",
    "因此：\n",
    "$$\n",
    "\\det(\\mathbf{L}_{Y_g \\cup \\{i\\}}) = \\det(\\mathbf{M})^2 = (\\det(\\mathbf{V}) \\cdot d_i)^2 = \\det(\\mathbf{V})^2 \\cdot d_i^2\n",
    "$$\n",
    "\n",
    "而由于 $\\mathbf{L}_{Y_g} = \\mathbf{V}\\mathbf{V}^T$，所以：\n",
    "$$\n",
    "\\det(\\mathbf{L}_{Y_g}) = \\det(\\mathbf{V}\\mathbf{V}^T) = \\det(\\mathbf{V})^2\n",
    "$$\n",
    "\n",
    "最终得到：\n",
    "$$\n",
    "\\det(\\mathbf{L}_{Y_g \\cup \\{i\\}}) = \\det(\\mathbf{L}_{Y_g}) \\cdot d_i^2\n",
    "$$\n",
    "\n",
    "因此，$\\det(\\mathbf{L}_{\\mathbf{Y}_g \\cup \\{i\\}})$的计算可以表示为：\n",
    "$$\n",
    "\\det(\\mathbf{L}_{\\mathbf{Y}_g \\cup \\{i\\}}) = \\det(\\mathbf{L}_{\\mathbf{Y}_g}) \\cdot \\det(d_i^2) = \\det(\\mathbf{L}_{\\mathbf{Y}_g}) \\cdot d_i^2\n",
    "$$\n",
    "\n",
    "再将$\\det(\\mathbf{L}_{\\mathbf{Y}_g \\cup \\{i\\}})$的结果代入优化目标 :eqref:`eq-dpp-marginal-gain` 可得：\n",
    "\n",
    "$$\n",
    "j = \\arg\\max_{i \\in Z \\setminus Y_g} \\log(d_i^2).\n",
    "$$\n",
    "\n",
    "如果上式得解，即可以得到$L_{Y_k \\cup \\{j\\}}$的Cholesky分解：\n",
    "$$\n",
    "L_{Y_k \\cup \\{j\\}} = \\begin{bmatrix}\n",
    "V & 0 \\\\\n",
    "c_j & d_j\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "V & 0 \\\\\n",
    "c_j & d_j\n",
    "\\end{bmatrix}^T\n",
    "$$\n",
    "\n",
    "按照上述的思路，如果$c_j$和$d_j$被求解出来了，$Y_g$就会被更新。在此基础上，对于未被选中的内容$i$，我们可以快速的计算出对应的$c_i'$和$d_i'$\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "V & 0 \\\\\n",
    "c_j & d_j\n",
    "\\end{bmatrix}\n",
    "c_i^T = \\mathbf{L}_{Y_g \\cup \\{j\\}, i} = \\begin{bmatrix}\n",
    "\\mathbf{L}_{Y_g, i} \\\\\n",
    "\\mathbf{L}_{j,i}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "即(详细推导不展开)：\n",
    "$$\n",
    "c_i' = [c_i \\quad (L_{ji} - \\langle c_j, c_i \\rangle)/d_j] = [c_i \\quad e_i]\n",
    "$$\n",
    "\n",
    "$$\n",
    "d_i^2 = L_{ii} - \\|c_i\\|_2^2 = L_{ii} - \\|c_i\\|_2^2 - c_i^2 = d_i^2 - c_i^2\n",
    "$$\n",
    "\n",
    "当 $d_i'$ 得到之后可根据 $j = \\arg\\max_{i \\in Z \\setminus Y_g} \\log(d_i^2)$ 得到最优的内容放入到 $Y_g$中。\n",
    "\n",
    "**最终贪心算法的算法流程如下**\n",
    "\n",
    "1. 初始化：\n",
    "   - $\\mathbf{c}_i = [], d_i^2 = \\mathbf{L}_{ii}, j = \\arg\\max_{i \\in Z} \\log(d_i^2), Y_g = \\{j\\}$\n",
    "\n",
    "2. 迭代：\n",
    "   - 当停止条件不满足时，执行以下步骤：\n",
    "     - 对于每个 $i \\in Z \\setminus Y_g$：\n",
    "       - 计算 $\\mathbf{e}_i = (\\mathbf{L}_{ji} - \\langle \\mathbf{c}_j, \\mathbf{c}_i \\rangle) / d_j$\n",
    "       - 更新 $\\mathbf{c}_i = [\\mathbf{c}_i \\quad \\mathbf{e}_i], d_i^2 = d_i^2 - \\mathbf{e}_i^2$\n",
    "       - 选择 $j = \\arg\\max_{i \\in Z \\setminus Y_g} \\log(d_i^2)$，更新 $Y_g = Y_g \\cup \\{j\\}$\n",
    "\n",
    "3. 返回：返回 $Y_g$\n",
    "\n",
    "\n",
    "DPP贪心求解算法的代码实现如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5933281f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T06:19:08.776328Z",
     "iopub.status.busy": "2025-10-13T06:19:08.775278Z",
     "iopub.status.idle": "2025-10-13T06:19:20.449403Z",
     "shell.execute_reply": "2025-10-13T06:19:20.448684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始构建核矩阵...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "核矩阵生成完成！\n",
      "算法运行时间: \t3.9285e-02\n",
      "选择了 50 个物品\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import math\n",
    "import time\n",
    "from typing import Any, Callable, Dict, List\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Item:\n",
    "    def __init__(\n",
    "        self,\n",
    "        id: str,\n",
    "        rel: float,\n",
    "        dense_vector: List[float] = None,\n",
    "        sparse_features: Dict[str, Any] = None\n",
    "    ) -> None:\n",
    "        self.id = id\n",
    "        self.rel = rel  # 相关性分数（精排分）\n",
    "        self.dense_vector = dense_vector  # 稠密向量表示（如嵌入向量）\n",
    "        self.sparse_features = sparse_features  # 稀疏特征（标签、类别、作者等）\n",
    "\n",
    "def DPP_Reranking(\n",
    "    item_pool: List[Item],\n",
    "    k: int,\n",
    "    kernel_matrix: np.ndarray,\n",
    "    epsilon: float = 1E-10) -> List[Item]:\n",
    "    \"\"\"\n",
    "    基于行列式点过程(DPP)的贪心重排实现\n",
    "\n",
    "    参数:\n",
    "    item_pool -- 候选物品列表\n",
    "    k -- 最终返回的物品数量\n",
    "    kernel_matrix -- 核矩阵，融合了相关性和多样性\n",
    "    epsilon -- 数值稳定性阈值\n",
    "\n",
    "    返回:\n",
    "    重排后的物品列表\n",
    "    \"\"\"\n",
    "    # 创建副本避免修改原始输入\n",
    "    candidates = copy.deepcopy(item_pool)\n",
    "    item_size = len(candidates)\n",
    "\n",
    "    if not candidates or k <= 0:\n",
    "        return []\n",
    "\n",
    "    # 初始化Cholesky分解相关变量\n",
    "    cis = np.zeros((k, item_size))  # 存储c_i向量\n",
    "    di2s = np.copy(np.diag(kernel_matrix))  # 存储d_i^2值\n",
    "    selected_items = []  # 已选择物品的索引\n",
    "\n",
    "    # 第一步：选择初始物品（d_i^2最大的物品）\n",
    "    selected_item_idx = np.argmax(di2s)\n",
    "    selected_items.append(selected_item_idx)\n",
    "\n",
    "    # 第二步：贪心迭代选择\n",
    "    while len(selected_items) < k and len(selected_items) < item_size:\n",
    "        k_current = len(selected_items) - 1  # 当前迭代轮次\n",
    "\n",
    "        # 获取当前选中物品的c_i和d_i\n",
    "        ci_optimal = cis[:k_current, selected_item_idx]\n",
    "        di_optimal = math.sqrt(di2s[selected_item_idx])\n",
    "\n",
    "        # 计算与当前选中物品的核矩阵元素\n",
    "        elements = kernel_matrix[selected_item_idx, :]\n",
    "\n",
    "        # 更新所有候选物品的c_i和d_i^2\n",
    "        # e_i = (L_{ji} - <c_j, c_i>) / d_j\n",
    "        eis = (elements - np.dot(ci_optimal, cis[:k_current, :])) / di_optimal\n",
    "        cis[k_current, :] = eis\n",
    "\n",
    "        # 更新d_i^2 = d_i^2 - e_i^2\n",
    "        di2s -= np.square(eis)\n",
    "\n",
    "        # 选择下一个物品：argmax log(d_i^2)\n",
    "        selected_item_idx = np.argmax(di2s)\n",
    "\n",
    "        # 数值稳定性检查\n",
    "        if di2s[selected_item_idx] < epsilon:\n",
    "            break\n",
    "\n",
    "        selected_items.append(selected_item_idx)\n",
    "\n",
    "    # 根据选中的索引返回对应的物品\n",
    "    result = [candidates[idx] for idx in selected_items]\n",
    "    return result\n",
    "\n",
    "def create_kernel_matrix(\n",
    "    item_pool: List[Item],\n",
    "    sim_func: Callable[[Item, Item], float]\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    构建DPP核矩阵，融合相关性和多样性\n",
    "\n",
    "    参数:\n",
    "    item_pool -- 候选物品列表\n",
    "    sim_func -- 物品相似度计算函数\n",
    "\n",
    "    返回:\n",
    "    核矩阵 L = diag(r) * S * diag(r)\n",
    "    \"\"\"\n",
    "    n = len(item_pool)\n",
    "\n",
    "    # 构建相关性向量\n",
    "    relevance_scores = np.array([item.rel for item in item_pool])\n",
    "\n",
    "    # 构建相似度矩阵\n",
    "    similarity_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                similarity_matrix[i, j] = 1.0\n",
    "            else:\n",
    "                similarity_matrix[i, j] = sim_func(item_pool[i], item_pool[j])\n",
    "\n",
    "    # 构建核矩阵: L = diag(r) * S * diag(r)\n",
    "    kernel_matrix = (\n",
    "        relevance_scores.reshape((n, 1)) *\n",
    "        similarity_matrix *\n",
    "        relevance_scores.reshape((1, n))\n",
    "    )\n",
    "\n",
    "    return kernel_matrix\n",
    "\n",
    "# 生成测试数据\n",
    "item_size = 1000\n",
    "feature_dimension = 100\n",
    "max_length = 50\n",
    "\n",
    "# 创建测试物品\n",
    "test_items = []\n",
    "for i in range(item_size):\n",
    "    rel_score = np.exp(0.01 * np.random.randn() + 0.2)\n",
    "    dense_vec = np.random.randn(feature_dimension)\n",
    "    dense_vec /= np.linalg.norm(dense_vec)  # 归一化\n",
    "\n",
    "    item = Item(\n",
    "        id=f\"item_{i}\",\n",
    "        rel=rel_score,\n",
    "        dense_vector=dense_vec.tolist()\n",
    "    )\n",
    "    test_items.append(item)\n",
    "\n",
    "# 定义相似度函数\n",
    "def cosine_similarity_func(item1: Item, item2: Item) -> float:\n",
    "    vec1 = np.array(item1.dense_vector)\n",
    "    vec2 = np.array(item2.dense_vector)\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# 构建核矩阵\n",
    "print('开始构建核矩阵...')\n",
    "kernel_matrix = create_kernel_matrix(test_items, cosine_similarity_func)\n",
    "print('核矩阵生成完成！')\n",
    "\n",
    "# 执行DPP重排\n",
    "t = time.time()\n",
    "result = DPP_Reranking(test_items, max_length, kernel_matrix)\n",
    "print('算法运行时间: ' + '\\t' + \"{0:.4e}\".format(time.time() - t))\n",
    "print(f'选择了 {len(result)} 个物品')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}