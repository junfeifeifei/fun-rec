{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "679ce948",
   "metadata": {},
   "source": [
    "# 多塔结构\n",
    ":label:`multi_tower`\n",
    "\n",
    "在多目标建模领域，如 MMoE 所展现的那样，专家网络（Expert）承担着挖掘不同任务之间共享的底层特征表示的重任，而门控网络（Gate）则灵活地动态分配专家权重，依据不同任务的特性需求进行精准适配。这种由 “共享专家 + 任务专属门控” 构成的架构，与生俱来地具备处理共性（共享专家所提取的通用特征）与特性（门控网络赋予的特定权重）的卓越能力。\n",
    "\n",
    "多场景建模与多任务学习类似但关注点不同：多任务学习处理相同场景/分布下的不同任务（如单样本同时预估CTR、CVR），而多场景建模处理不同场景/分布下的相同任务（如不同场景预估相同CTR）。前者是对于一条样本预估多个不同的目标值，后者是对于不同的样本预估相同的目标值。多场景建模若采用独立模型，会忽视场景共性，导致小场景效果差且资源消耗剧增；若混合样本训练单一模型，则会忽视场景差异，降低预测精度。\n",
    "\n",
    "![多目标与多场景建模的差异(图片来自阿里妈妈博客)](../../img/star_1.png)\n",
    ":width:`500px`\n",
    ":label:`multi_tower_diff`\n",
    "\n",
    "本小节将会介绍基于多塔结构建模时，在利用多场景共性的前提下，显示的使用不同场景的信号来捕捉场景的特性。\n",
    "\n",
    "## HMoE\n",
    "\n",
    "在多任务建模小节中，介绍了MMoE（Mixture-of-Experts）底层通过多专家网络作为多任务的共享特征，顶层对于不同的任务使用门控机制融合专家特征实现不同任务差异化的学习。在多场景建模中HMoE借鉴了MMoE的思路，底层同样适用多专家网络提取提取多个场景的特征作为共享特征，只不过顶层的多个塔不再是多个任务的输出，而是多个场景的输出，HMoE模型结构如下：\n",
    "\n",
    "![HMoE模型结构](../../img/hmoe.png)\n",
    ":width:`300px`\n",
    ":label:`hmoe_model_structure`\n",
    "\n",
    "模型的底层使用多个专家抽取多个场景的特征，并通过一组门控网络将多个专家的输出结果进行融合，最后输入给上层不同的场景塔。\n",
    "\n",
    "$$\n",
    "M(x) = \\sum_{i=1}^{K} G_i(x) E_i(x)\n",
    "$$\n",
    "\n",
    "原论文中是对于所有场景的塔都使用同一组门控融合后的专家特征，这种方式可以看成是多任务建模中的Shared-Bottom式的特征共享，只不过以多个FCN的融合输出替代了单个FCN的输出。从MMoE的经验来看，如果多个任务之间的相关性较差，底层这种特征硬共享可能会出现负迁移的现象。所以这种方式也不一定就是多场景建模的最优方案，也可以尝试对于不同的场景，使用不同门控融合后的专家特征。如第$t$个场景的输入特征表示为$M_t(x) = \\sum_{i=1}^{K} G_i^t(x) E_i(x)$，最终哪种效果更好可以根据自己的场景做实验得到。\n",
    "\n",
    "在得到了底层多场景特征之后，模型单场景的最终预估值不是简单的直接使用对应场景Tower打分，而是将多个场景输出打分融合为单个场景的打分。第$t$个场景的模型打分表示如下：\n",
    "\n",
    "$$out_t = \\sum_{i=1}^{T} W_i(x) S_i(x)$$\n",
    "\n",
    "其中$W_i(x)$是场景$i$的融合权重，原论文中对于不同的场景下打分融合的$W$是否共享也未明确说明，但可以根据MMoE的思路，给每个场景都学习一个融合的权重，即第$t$个场景的预估值可以表示为：$out_t = \\sum_{i=1}^{T} W_i^t(x) S_i(x)$\n",
    "\n",
    "\n",
    "从最终单场景由多个场景打分融合可以看出，对于某个场景$t$的样本，HMoE不仅需要计算它在场景$t$下的打分，还需要计算它在场景下的打分，计算场景$t$最终的打分时，其他场景的打分对$t$场景也是有参考价值的。\n",
    "\n",
    "虽然在前向推理时可以将一条样本预估出不同场景的打分，但是对于某个场景$t$的样本来说应该只影响当前场景的参数（主要是场景塔的参数），否则$a$场景下的样本直接影响$b$场景的参数，很容易导致模型对于场景的感知下降，进而让整个多场景的模型效果变差。因此在计算融合打分时候，需要抑制其他场景打分的梯度回传，最终场景$t$的打分表示如下\n",
    "\n",
    "$$\n",
    "out_t(x) = W_t(x) S_t(x) + \\sum_{j=1, j \\neq t}^{T} W_j(x) \\underbrace{S_j(x)}_{\\text{stop gradient}}\n",
    "$$\n",
    "\n",
    "不共享融合权重的打分公式为：$out_t(x) = W_t^t(x) S_t(x) + \\sum_{j=1, j \\neq t}^{T} W_j^t(x) \\underbrace{S_j(x)}_{\\text{stop gradient}}$\n",
    "\n",
    "HMoE核心代码如下，其中包括了是否共享门控和融合打分权重的部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a44772c",
   "metadata": {},
   "source": [
    "```python\n",
    "def build_hmoe_model(feature_columns,\n",
    "                     num_domains,\n",
    "                     domain_feature_name,\n",
    "                     share_gate=False,\n",
    "                     share_domain_w=False,\n",
    "                     shared_expert_nums=5,\n",
    "                     shared_expert_dnn_units=[256,128],\n",
    "                     gate_dnn_units=[256,128],\n",
    "                     domain_tower_units=[128,64],\n",
    "                     domain_weight_units=[128,64],\n",
    "                     linear_logits=False\n",
    "                     ):\n",
    "    # 构建输入层字典\n",
    "    input_layer_dict = build_input_layer(feature_columns)\n",
    "    domain_input = input_layer_dict[domain_feature_name]\n",
    "    # 构建特征嵌入表字典\n",
    "    group_embedding_feature_dict = build_group_feature_embedding_table_dict(feature_columns, input_layer_dict, prefix=\"embedding/\")\n",
    "\n",
    "    # 连接不同组的嵌入向量作为各个网络的输入\n",
    "    dnn_inputs = concat_group_embedding(group_embedding_feature_dict, 'dnn')\n",
    "\n",
    "    # 创建多个专家\n",
    "    expert_output_list = []\n",
    "    for i in range(shared_expert_nums):\n",
    "        expert_output = DNNs(shared_expert_dnn_units, name=f\"expert_{str(i)}\")(dnn_inputs)\n",
    "        expert_output_list.append(expert_output)\n",
    "    expert_concat = tf.keras.layers.Lambda(lambda x: tf.stack(x, axis=1))(expert_output_list) # (None, expert_num, dims)\n",
    "\n",
    "    if share_gate:\n",
    "        # 共享Gate\n",
    "        domain_tower_input_list = []\n",
    "        gate_output = DNNs(gate_dnn_units, name=f\"shared_gates\")(dnn_inputs) \n",
    "        gate_output = tf.keras.layers.Dense(shared_expert_nums, use_bias=False, activation='softmax', name=f\"domain_{i}_softmax\")(gate_output)\n",
    "        gate_output = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1))(gate_output) # (None,expert_num, 1)\n",
    "        gate_expert_output = tf.keras.layers.Lambda(lambda x: x[0] * x[1])([gate_output, expert_concat])\n",
    "        gate_expert_output = tf.keras.layers.Lambda(lambda x: tf.reduce_sum(x, axis=1, keepdims=False))(gate_expert_output)\n",
    "        for _ in range(num_domains):\n",
    "            domain_tower_input_list.append(gate_expert_output)\n",
    "    else:\n",
    "        domain_tower_input_list = []\n",
    "        for i in range(num_domains):\n",
    "            gate_output = DNNs(gate_dnn_units, name=f\"domain_{str(i)}_gates\")(dnn_inputs) \n",
    "            gate_output = tf.keras.layers.Dense(shared_expert_nums, use_bias=False, activation='softmax', name=f\"domain_{i}_softmax\")(gate_output)\n",
    "            gate_output = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1))(gate_output) # (None,expert_num, 1)\n",
    "            gate_expert_output = tf.keras.layers.Lambda(lambda x: x[0] * x[1])([gate_output, expert_concat])\n",
    "            gate_expert_output = tf.keras.layers.Lambda(lambda x: tf.reduce_sum(x, axis=1, keepdims=False))(gate_expert_output)\n",
    "            for _ in range(num_domains):\n",
    "                domain_tower_input_list.append(gate_expert_output)\n",
    "\n",
    "    # 定义domain tower\n",
    "    domain_tower_output_list = []\n",
    "    for i in range(num_domains):\n",
    "        domain_dnn_input = domain_tower_input_list[i]\n",
    "        task_output = DNNs(domain_tower_units)(domain_dnn_input)\n",
    "        domain_tower_output_list.append(task_output)\n",
    "\n",
    "    # 定义domain权重\n",
    "    domain_weight_list = []\n",
    "    if share_domain_w:\n",
    "        # 共享domain权重\n",
    "        domain_weight = DNNs(domain_weight_units)(dnn_inputs)\n",
    "        for i in range(num_domains):\n",
    "           domain_weight_list.append(domain_weight) \n",
    "    else:\n",
    "        for i in range(num_domains):\n",
    "            domain_weight = DNNs(domain_weight_units)(dnn_inputs)\n",
    "            domain_weight = tf.keras.layers.Lambda(lambda x: tf.nn.softmax(x, axis=1))(domain_weight)\n",
    "            domain_weight_list.append(domain_weight)\n",
    "\n",
    "    # 融合domain信息\n",
    "    domain_output_list = []\n",
    "    for i in range(num_domains):\n",
    "        domain_weight = domain_weight_list[i]\n",
    "        domain_tower_output = domain_tower_output_list[i]\n",
    "        weighted_output = tf.keras.layers.Lambda(lambda x: x[0] * x[1])([domain_weight, domain_tower_output])\n",
    "        for j in  range(num_domains):\n",
    "            if i == j:\n",
    "                continue\n",
    "            grad_output = tf.keras.layers.Lambda(lambda x: tf.stop_gradient(x))(domain_tower_output_list[j])\n",
    "            weighted_output = tf.keras.layers.Add()([\n",
    "                weighted_output,\n",
    "                tf.keras.layers.Multiply()([domain_weight_list[i][:, j:j+1], grad_output])\n",
    "            ])\n",
    "        dummy_domain = tf.keras.layers.Lambda(lambda x: tf.ones_like(x[0]) * tf.cast(x[1], tf.int32))([domain_input, i])\n",
    "        domain_mask = tf.keras.layers.Lambda(lambda x: tf.squeeze(tf.equal(x[0], x[1]), axis=-1))([domain_input, dummy_domain])\n",
    "        domain_output = tf.keras.layers.Lambda(lambda x: tf.boolean_mask(x[0], x[1]))([weighted_output, domain_mask])\n",
    "        domain_output_list.append(domain_output)\n",
    "    # 将所有domain的数据拼接成batch\n",
    "    final_domain_output = tf.keras.layers.Concatenate(axis=0)(domain_output_list)\n",
    "    dnn_logits = PredictLayer(activation=None, name=\"dnn_logits\")(final_domain_output)\n",
    "\n",
    "    if linear_logits:\n",
    "        linear_logits = get_linear_logits(input_layer_dict, feature_columns)\n",
    "        final_logits = dnn_logits + linear_logits\n",
    "    else:\n",
    "        final_logits = dnn_logits\n",
    "\n",
    "    # 构建模型\n",
    "    model = tf.keras.Model(inputs=list(input_layer_dict.values()), outputs=final_logits)\n",
    "    return model\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7a77ad",
   "metadata": {},
   "source": [
    "完整的实践流程：\n",
    "**1. 导入相关代码包**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80cf0ef1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T06:16:24.781884Z",
     "iopub.status.busy": "2025-10-13T06:16:24.781733Z",
     "iopub.status.idle": "2025-10-13T06:16:31.982556Z",
     "shell.execute_reply": "2025-10-13T06:16:31.981300Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import funrec\n",
    "from funrec.utils import build_metrics_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c2e09b",
   "metadata": {},
   "source": [
    "**2. 特征处理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c9427f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T06:16:31.988230Z",
     "iopub.status.busy": "2025-10-13T06:16:31.987510Z",
     "iopub.status.idle": "2025-10-13T06:16:35.421651Z",
     "shell.execute_reply": "2025-10-13T06:16:35.420823Z"
    }
   },
   "outputs": [],
   "source": [
    "config = funrec.load_config('hmoe')\n",
    "train_data, test_data = funrec.load_data(config.data)\n",
    "feature_columns, processed_data = funrec.prepare_features(config.features, train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b6074c",
   "metadata": {},
   "source": [
    "**3. 模型定义及训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cc697c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T06:16:35.427349Z",
     "iopub.status.busy": "2025-10-13T06:16:35.426687Z",
     "iopub.status.idle": "2025-10-13T06:16:51.376516Z",
     "shell.execute_reply": "2025-10-13T06:16:51.375054Z"
    }
   },
   "outputs": [],
   "source": [
    "model = funrec.train_model(config.training, feature_columns, processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095fc4c7",
   "metadata": {},
   "source": [
    "**4. 模型效果评估**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bc012b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T06:16:51.385434Z",
     "iopub.status.busy": "2025-10-13T06:16:51.384800Z",
     "iopub.status.idle": "2025-10-13T06:16:59.978459Z",
     "shell.execute_reply": "2025-10-13T06:16:59.977434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+------------+\n",
      "|    auc |   gauc |   val_user |\n",
      "+========+========+============+\n",
      "| 0.5811 | 0.5448 |        217 |\n",
      "+--------+--------+------------+\n"
     ]
    }
   ],
   "source": [
    "metrics = funrec.evaluate_model(model, processed_data, config.evaluation, feature_columns)\n",
    "print(build_metrics_table(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685fe9ba",
   "metadata": {},
   "source": [
    "## STAR\n",
    "\n",
    "STAR（Star Topology Adaptive Recommender）模型采用星型拓扑结构，实现场景私有参数和场景共享参数同时建模场景差异性和共性。场景私有参数以及场景共享参数最终聚合得到每个场景的模型。STAR结构如下图所示。\n",
    "\n",
    "![STAR模型结构](../../img/star_2.png)\n",
    ":width:`500px`\n",
    ":label:`star_model_structure`\n",
    "\n",
    "相比于单场景的模型，STAR有三个针对多场景建模的创新思路值得学习，分别是星型拓扑结构的全连接网络（STAR Topology Fully-Connected Network），Partitioned Normalization 以及辅助网络，下面将以此进行介绍。\n",
    "\n",
    "**STAR Topology Fully-Connected Network**\n",
    "\n",
    "星形拓扑全连接结构的核心思想是对于每一个全连接网络（FCN）都有场景共享和场景独占的部分，每个场景最终的参数由共享和独占参数通过element-wise product融合计算得到。\n",
    "\n",
    "![STAR FCN结构](../../img/star_fcn.png)\n",
    ":width:`400px`\n",
    ":label:`star_fcn_structure`\n",
    "\n",
    "具体而言，对于第$p$个场景的FCN的最终参数$W_p^{\\star},b_p^{\\star}$表示如下：\n",
    "$$\n",
    "W_p^{\\star} = W_p \\otimes W \\\\\n",
    "b_p^{\\star} = b_p + b\n",
    "$$\n",
    "其中$W_p,W$分别表示第$p$个场景独有和全场景共享的参数，$b_p,b$也一样。\n",
    "\n",
    "如果用$in_p$表示第$p$个场景FCN的输入，则该层星形FCN的输出$out_p$表示为：\n",
    "$$\n",
    "out_p = \\phi((W_p^\\star)^\\top in_p + b_p^\\star),\n",
    "$$\n",
    "其中$\\phi$是激活函数。\n",
    "\n",
    "STAR Topology Fully-Connected Network的具体实现如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0de8db",
   "metadata": {},
   "source": [
    "```python\n",
    "class StarTopologyFCN(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 num_domain,\n",
    "                 hidden_units,\n",
    "                 activation=\"relu\",\n",
    "                 dropout=0.,\n",
    "                 l2_reg=0.,\n",
    "                 **kwargs):\n",
    "        self.num_domain = num_domain\n",
    "        self.hidden_units = hidden_units\n",
    "        self.activation_list = [tf.keras.layers.Activation(activation) for _ in hidden_units]\n",
    "        self.dropout_list = [tf.keras.layers.Dropout(dropout) for _ in hidden_units]\n",
    "        self.l2_reg = l2_reg\n",
    "        super(StarTopologyFCN, self).__init__( **kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_shape = input_shape[0]\n",
    "\n",
    "        self.shared_bias = [\n",
    "            self.add_weight(\n",
    "                name=f\"shared_bias_{i}\",\n",
    "                shape=[1, i],\n",
    "                initializer=tf.keras.initializers.Zeros(),\n",
    "                trainable=True\n",
    "            ) for i in self.hidden_units\n",
    "        ]\n",
    "        self.domain_bias_list = [\n",
    "            tf.keras.layers.Embedding(\n",
    "                self.num_domain,\n",
    "                output_dim=i,\n",
    "                embeddings_initializer=tf.keras.initializers.Zeros()\n",
    "            ) for i in self.hidden_units\n",
    "        ]\n",
    "\n",
    "        hidden_units = self.hidden_units.copy()\n",
    "        hidden_units.insert(0, input_shape[-1])\n",
    "        self.shared_weights = [\n",
    "            self.add_weight(\n",
    "                name=f\"shared_weight_{i}\",\n",
    "                shape=[1, hidden_units[i], hidden_units[i+1]],\n",
    "                initializer=\"glorot_uniform\",\n",
    "                regularizer=tf.keras.regularizers.l2(self.l2_reg),\n",
    "                trainable=True\n",
    "            ) for i in range(len(hidden_units) - 1)\n",
    "        ]\n",
    "        self.domain_weights_list = [\n",
    "            tf.keras.layers.Embedding(\n",
    "                self.num_domain,\n",
    "                hidden_units[i] * hidden_units[i + 1],\n",
    "                embeddings_initializer=\"glorot_uniform\",\n",
    "                embeddings_regularizer=tf.keras.regularizers.l2(self.l2_reg)\n",
    "            ) for i in range(len(hidden_units) - 1)\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        inputs, domain_index = inputs\n",
    "        output = tf.expand_dims(inputs, axis=1)\n",
    "        for i in range(len(self.hidden_units)):\n",
    "            domain_weight = tf.reshape(self.domain_weights_list[i](domain_index),\n",
    "                                       [-1] + self.shared_weights[i].shape.as_list()[1:])\n",
    "            weight = self.shared_weights[i] * domain_weight\n",
    "            domain_bias = tf.reshape(self.domain_bias_list[i](domain_index), [-1] + self.shared_bias[i].shape.as_list()[1:])\n",
    "            bias = self.shared_bias[i] + domain_bias\n",
    "\n",
    "            fc = tf.matmul(output, weight) + tf.expand_dims(bias, 1)\n",
    "            output = self.activation_list[i](fc, training=training)\n",
    "            output = self.dropout_list[i](output, training=training)\n",
    "\n",
    "        return tf.squeeze(output, axis=1)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b13a03a",
   "metadata": {},
   "source": [
    "**Partitioned Normalization**\n",
    "\n",
    "在神经网络训练时，为了加快模型的收敛常会在模型中加入BN(Batch Normalization)。但是在多场景建模中，样本只在相同的场景内才满足独立同分布，多个场景混合的样本得到的统计量会忽略了不同场景独有的分布差异。为此应该让多场景中不同的场景独享统计量，这就是PN(Partitioned Normalization)提出的主要动机。\n",
    "\n",
    "在介绍PN之前，先简单回顾一下经典的BN的原理：\n",
    "$$\n",
    "\\mathbf{z'} = \\gamma \\frac{\\mathbf{z} - \\mathbf{E}}{\\sqrt{\\mathrm{Var} + \\epsilon}} + \\beta\n",
    "$$\n",
    "其中$\\mathbf{E},\\mathrm{Var}$分别是移动的均值和方差，$\\gamma,\\beta$是可学习的参数用来对数据进行缩放和平移。\n",
    "\n",
    "PN相比BN来说，不仅可学习的缩放和平移参数包括场景共享和独占两部分的参数，统计的移动均值和方差也是在不同场景样本上得到的，具体表示如下：\n",
    "$$\n",
    "\\mathbf{z'} = (\\gamma * \\gamma_p) \\frac{\\mathbf{z} - \\mathbf{E_p}}{\\sqrt{\\mathrm{Var_p} + \\epsilon}} + (\\beta + \\beta_p)\n",
    "$$\n",
    "其中$\\gamma,\\beta$和$\\gamma_p,\\beta_p$分别表示场景共享和独占的参数，$\\mathbf{E_p},\\mathrm{Var_p}$表示在场景$p$的样本中统计得到的移动均值和方差。由于PN是基于Batch样本计算的，为了得到不同场景下更稳定的均值和方差，训练时的Batch Size可以调的稍微大一些。\n",
    "\n",
    "Partitioned Normalization的具体实现如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044bad11",
   "metadata": {},
   "source": [
    "```python\n",
    "class PartitionedNormalization(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 num_domain,\n",
    "                 name=None,\n",
    "                 **kwargs):\n",
    "\n",
    "        self.bn_list = [tf.keras.layers.BatchNormalization(center=False, scale=False, name=f\"bn_{i}\") for i in range(num_domain)]\n",
    "\n",
    "        super(PartitionedNormalization, self).__init__(name=name)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2 and len(input_shape[1]) <= 2\n",
    "        dim = input_shape[0][-1]\n",
    "\n",
    "        self.global_gamma = self.add_weight(\n",
    "            name=\"global_gamma\",\n",
    "            shape=[dim],\n",
    "            initializer=tf.keras.initializers.Constant(0.5),\n",
    "            trainable=True\n",
    "        )\n",
    "        self.global_beta = self.add_weight(\n",
    "            name=\"global_beta\",\n",
    "            shape=[dim],\n",
    "            initializer=tf.keras.initializers.Zeros(),\n",
    "            trainable=True\n",
    "        )\n",
    "        self.domain_gamma = self.add_weight(\n",
    "                name=\"domain_gamma\",\n",
    "                shape=[len(self.bn_list), dim],\n",
    "                initializer=tf.keras.initializers.Constant(0.5),\n",
    "                trainable=True\n",
    "            )\n",
    "        self.domain_beta = self.add_weight(\n",
    "                name=\"domain_beta\",\n",
    "                shape=[len(self.bn_list), dim],\n",
    "                initializer=tf.keras.initializers.Zeros(),\n",
    "                trainable=True\n",
    "            )\n",
    "\n",
    "    def generate_grid_tensor(self, indices, dim):\n",
    "        y = tf.range(dim)\n",
    "        x_grid, y_grid = tf.meshgrid(indices, y)\n",
    "        return tf.transpose(tf.stack([x_grid, y_grid], axis=-1), [1, 0, 2])\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        inputs, domain_index = inputs\n",
    "        domain_index = tf.cast(tf.reshape(domain_index, [-1]), \"int32\")\n",
    "        dim = inputs.shape.as_list()[-1]\n",
    "\n",
    "        output = inputs\n",
    "        # compute each domain's BN individually\n",
    "        for i, bn in enumerate(self.bn_list):\n",
    "            mask = tf.equal(domain_index, i)\n",
    "            single_bn = self.bn_list[i](tf.boolean_mask(inputs, mask), training=training)\n",
    "            single_bn = (self.global_gamma + self.domain_gamma[i]) * single_bn + (self.global_beta + self.domain_beta[i])\n",
    "\n",
    "            # get current domain samples' indices\n",
    "            indices = tf.boolean_mask(tf.range(tf.shape(inputs)[0]), mask)\n",
    "            indices = self.generate_grid_tensor(indices, dim)\n",
    "            output = tf.cond(\n",
    "                tf.reduce_any(mask),\n",
    "                lambda: tf.reshape(tf.tensor_scatter_nd_update(output, indices, single_bn), [-1, dim]),\n",
    "                lambda: output\n",
    "            )\n",
    "\n",
    "        return output\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b942b0d6",
   "metadata": {},
   "source": [
    "为了进一步加强场景特征对模型输出的影响，在STAR中还会单独构建一个场景的辅助网络(Auxiliary Network)，辅助网络将场景特征和其他特征共同输入到浅层网络中得到一个辅助的Logits，最终和主网络的Logits相加计算得到最终的CTR预估值：\n",
    "$$\n",
    "pCTR = Sigmoid(Logits_{main} + Logits_{aux})\n",
    "$$\n",
    "\n",
    "\n",
    "STAR模型的实现代码如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38222eb8",
   "metadata": {},
   "source": [
    "```python\n",
    "def build_star_model(\n",
    "                    feature_columns, \n",
    "                    num_domains, \n",
    "                    domain_feature_name,\n",
    "                    star_dnn_units=[128, 64],\n",
    "                    aux_dnn_units=[128, 64],\n",
    "                    star_fcn_activation='relu',\n",
    "                    dropout=0.2,\n",
    "                    l2_reg=1e-5,\n",
    "                    linear_logits=False):\n",
    "    # 构建输入层字典\n",
    "    input_layer_dict = build_input_layer(feature_columns)\n",
    "    domain_input = input_layer_dict[domain_feature_name]\n",
    "\n",
    "    # 构建特征嵌入表字典\n",
    "    group_embedding_feature_dict = build_group_feature_embedding_table_dict(feature_columns, input_layer_dict, prefix=\"embedding/\")\n",
    "\n",
    "    # 连接不同组的嵌入向量作为各个网络的输入\n",
    "    domain_embeddings = concat_group_embedding(group_embedding_feature_dict, 'domain')\n",
    "    dnn_inputs = concat_group_embedding(group_embedding_feature_dict, 'dnn')\n",
    "\n",
    "    fcn_inputs = PartitionedNormalization(num_domain=num_domains, name=\"fcn_pn_layer\")([dnn_inputs, domain_input])\n",
    "\n",
    "    fcn_output = StarTopologyFCN(num_domains, star_dnn_units, star_fcn_activation,\n",
    "                                dropout, l2_reg, name=\"star_fcn_layer\")([fcn_inputs, domain_input])\n",
    "\n",
    "    fcn_logit = PredictLayer(activation=None, name='fcn_logits')(fcn_output)\n",
    "    \n",
    "    aux_inputs = concat_func([domain_embeddings, dnn_inputs], axis=-1)\n",
    "    aux_inputs = PartitionedNormalization(num_domain=num_domains, name=\"aux_pn_layer\")([aux_inputs, domain_input])\n",
    "\n",
    "    aux_output = DNNs(aux_dnn_units, dropout_rate=dropout)(aux_inputs)\n",
    "    aux_logit = PredictLayer(activation=None, name='aux_logits')(aux_output)\n",
    "\n",
    "    if linear_logits:\n",
    "        linear_logits = get_linear_logits(input_layer_dict, feature_columns)\n",
    "        final_logits = add_tensor_func([linear_logits, fcn_logit, aux_logit])\n",
    "    else:\n",
    "        final_logits = add_tensor_func([fcn_logit, aux_logit])\n",
    "\n",
    "    final_prediction = PredictLayer(activation=None, name='final_prediction')(final_logits)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=list(input_layer_dict.values()), outputs=final_prediction)\n",
    "    return model\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab17be8e",
   "metadata": {},
   "source": [
    "完整的实践流程：\n",
    "**1. 导入相关代码包**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f03d41f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T06:17:00.047633Z",
     "iopub.status.busy": "2025-10-13T06:17:00.039921Z",
     "iopub.status.idle": "2025-10-13T06:17:00.055275Z",
     "shell.execute_reply": "2025-10-13T06:17:00.054764Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import funrec\n",
    "from funrec.utils import build_metrics_table, print_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818bfccf",
   "metadata": {},
   "source": [
    "**2. 特征处理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b7811c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T06:17:00.078321Z",
     "iopub.status.busy": "2025-10-13T06:17:00.077995Z",
     "iopub.status.idle": "2025-10-13T06:17:03.835597Z",
     "shell.execute_reply": "2025-10-13T06:17:03.827605Z"
    }
   },
   "outputs": [],
   "source": [
    "config = funrec.load_config('star')\n",
    "train_data, test_data = funrec.load_data(config.data)\n",
    "feature_columns, processed_data = funrec.prepare_features(config.features, train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f734c77a",
   "metadata": {},
   "source": [
    "**3. 模型定义及训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a7e285f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T06:17:03.848851Z",
     "iopub.status.busy": "2025-10-13T06:17:03.845842Z",
     "iopub.status.idle": "2025-10-13T06:17:28.762085Z",
     "shell.execute_reply": "2025-10-13T06:17:28.761164Z"
    }
   },
   "outputs": [],
   "source": [
    "model = funrec.train_model(config.training, feature_columns, processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3e75e5",
   "metadata": {},
   "source": [
    "**4. 模型效果评估**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8163b6e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T06:17:28.765445Z",
     "iopub.status.busy": "2025-10-13T06:17:28.765183Z",
     "iopub.status.idle": "2025-10-13T06:17:42.939198Z",
     "shell.execute_reply": "2025-10-13T06:17:42.938578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------+\n",
      "|      auc |     gauc |   val_user |\n",
      "+==========+==========+============+\n",
      "| 0.642177 | 0.615368 |        693 |\n",
      "+----------+----------+------------+\n"
     ]
    }
   ],
   "source": [
    "metrics = funrec.evaluate_model(model, processed_data, config.evaluation, feature_columns)\n",
    "print_table(metrics)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}